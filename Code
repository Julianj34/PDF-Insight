import os
import fitz  # PyMuPDF for PDF parsing
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor
import time

# Load environment variables
load_dotenv()

# Setup ChatGPT Model (can be adjusted based on OpenAI account settings)
MODEL_NAME = os.getenv("GPT_MODEL", "gpt-4o")
TEMPERATURE = float(os.getenv("GPT_TEMPERATURE", 0.3))

chatgpt_model = ChatOpenAI(model_name=MODEL_NAME, temperature=TEMPERATURE)

# Universal Makro-Prompt for Comprehensive Paper Analysis
MACRO_PROMPT = '''
Conduct a comprehensive, systemic analysis of this scientific paper based on the following five core principles:

1. Systemic Definition (Central Questions and Objectives)
2. Interdisciplinarity (Relevant Disciplines)
3. Deep Data & Networking (Key Data Sources)
4. Pattern Recognition (Core Patterns and Mechanisms)
5. Validation & Creativity (Critical Points and Innovations)

Create a structured, interdisciplinary synthesis that reveals systemic connections, identifies key patterns, and integrates innovative approaches for problem-solving.
'''

# Individual Micro-Prompts for Detailed Analysis
PROMPTS = {
    PROMPTS = {
    "Systemic Definition": "Formulate the central research questions and long-term objectives of this paper. What systemic connections are intended to be understood? Which fundamental principles are the focus?",
    "Interdisciplinarity": "Identify the relevant scientific disciplines that can contribute to solving this research question. Which synergies between established and emerging research fields are critical to achieving a comprehensive understanding?",
    "Deep Data & Networking": "Determine the key data sources and networks necessary to gain deep insights into the system. Which data must be connected, analyzed, and integrated to capture the full complexity of the system?",
    "Pattern Recognition": "Identify the critical patterns, mechanisms, and emergent properties that shape the system. Which recurring structures, nonlinear dynamics, or critical transitions are relevant for developing innovative solutions?",
    "Validation & Creativity": "Put the results to the test. Which creative methods and alternative perspectives can be used to validate the hypotheses while fostering radical innovations?"
}


def extract_text_from_pdf(pdf_file):
    """Extracts all text from a given PDF file."""
    with fitz.open(pdf_file) as doc:
        text = "".join(page.get_text() for page in doc)
    return text


def count_tokens(text):
    """Counts the approximate number of tokens in a text."""
    return len(text.split())


def chunk_text(text, chunk_size=3500):
    """Splits the text into smaller chunks to avoid token limit errors."""
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]


def analyze_chunk(chunk, prompt):
    """Analyze a single chunk using the GPT model with a specific prompt."""
    while True:
        try:
            messages = [
                SystemMessage(content=prompt),
                HumanMessage(content=chunk)
            ]
            response = chatgpt_model.invoke(messages)
            return response.content.strip()
        except Exception as e:
            if "rate_limit_exceeded" in str(e).lower():
                print("Rate-Limit erreicht. Warte 60 Sekunden...")
                time.sleep(60)
            else:
                print(f"Fehler bei der Analyse eines Chunks: {e}")
                return f"Fehler: {e}"


def analyze_paper(pdf_file, output_file):
    """Analyze the given research paper using the GPT model with both macro and micro prompts."""
    paper_text = extract_text_from_pdf(pdf_file)
    print(f"Anzahl der Tokens: {count_tokens(paper_text)}")
    chunks = chunk_text(paper_text, chunk_size=3500)
    results = []

    # Makro-Analyse
    print("Starte Makro-Analyse...")
    macro_results = [analyze_chunk(chunk, MACRO_PROMPT) for chunk in chunks]
    results.append("=== Makro-Analyse ===\n" + "\n\n".join(macro_results))

    # Mikro-Analysen
    for prompt_key, prompt in PROMPTS.items():
        print(f"Starte Analyse mit dem Prompt: {prompt_key}")
        prompt_results = [analyze_chunk(chunk, prompt) for chunk in chunks]
        results.append(f"=== {prompt_key} ===\n" + "\n\n".join(prompt_results))

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n\n".join(results))
    print(f"Analyse abgeschlossen. Ergebnis gespeichert in: {output_file}")


def main():
    pdf_file = input("Pfad zur PDF-Datei eingeben: ").strip()
    output_file = pdf_file.replace(".pdf", "_analysis.txt")

    if os.path.exists(pdf_file):
        print(f"Starte Analyse f√ºr Datei: {pdf_file}")
        analyze_paper(pdf_file, output_file)
    else:
        print(f"Datei '{pdf_file}' nicht gefunden.")


if __name__ == "__main__":
    main()
